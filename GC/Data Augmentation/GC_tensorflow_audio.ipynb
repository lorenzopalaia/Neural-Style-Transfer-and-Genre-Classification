{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_noise = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.7),\n",
    "])\n",
    "pitch_shift = Compose([\n",
    "    PitchShift(min_semitones=-4, max_semitones=12, p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "#setting melspec features\n",
    "n_mels = 128\n",
    "hop_length = 512\n",
    "n_fft = 1024\n",
    "\n",
    "\n",
    "#extract melspec features using librosa\n",
    "S = librosa.feature.melspectrogram(sample, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "\n",
    "#convert it to DB scale\n",
    "S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "#display the spectrogram\n",
    "librosa.display.specshow(S_DB, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel');\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary list for the input data\n",
    "data = []\n",
    "\n",
    "#list to append all the labels\n",
    "Y = []\n",
    "\n",
    "base_path = '../input/gtzan-dataset-music-genre-classification/Data/genres_original'\n",
    "\n",
    "#looping through all label directories\n",
    "for label in tqdm(os.listdir(base_path)):\n",
    "    file_path = base_path + '/' + label\n",
    "    \n",
    "    #looping through each file in the directory\n",
    "    for pth in os.listdir(file_path):\n",
    "        \n",
    "        try:\n",
    "            final_path = file_path + '/' + pth\n",
    "\n",
    "            #loading original file\n",
    "            audio, sr = librosa.load(final_path,duration = 28)\n",
    "            \n",
    "            #appending data to a list\n",
    "            data.append(audio)\n",
    "          \n",
    "\n",
    "            #appending labels to the label list\n",
    "            Y.append(label)\n",
    "            \n",
    "        except:\n",
    "            print(\"Error in file\", pth)\n",
    "            pass\n",
    "        \n",
    "#converting list to a numpy array\n",
    "X = np.stack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the data using the SkLearn library\n",
    "audio_train, audio_test, y_train, y_test = train_test_split(\\\n",
    "     X, Y, test_size=0.20, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspec(audio, sr = sr, n_fft = n_fft, hop_length = hop_length, n_mels = n_mels):\n",
    "    #calculate the melspectogram of the provided audio wave\n",
    "    S = librosa.feature.melspectrogram(audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary list for the input data\n",
    "X_train = []\n",
    "\n",
    "#list to append all the labels\n",
    "Y_train = []\n",
    "\n",
    "#looping through train data to create melspec and augment data\n",
    "for i, dat in tqdm(enumerate(audio_train)):\n",
    "        \n",
    "    try:\n",
    "\n",
    "        #adding noise to the file\n",
    "        noisy_audio = add_noise(dat ,sr)\n",
    "        #changing pitch of the audio\n",
    "        pitch_audio = pitch_shift(dat, sr)\n",
    "\n",
    "        #generate melspec for original and augmented files\n",
    "        mel = get_melspec(dat)\n",
    "        noise_mel = get_melspec(noisy_audio)\n",
    "        pitch_mel = get_melspec(pitch_audio)\n",
    "\n",
    "        #appending augmented data to original training data\n",
    "        X_train.append(mel)\n",
    "        Y_train.append(y_train[i])\n",
    "        X_train.append(noise_mel)\n",
    "        Y_train.append(y_train[i])\n",
    "        X_train.append(pitch_mel)\n",
    "        Y_train.append(y_train[i])\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in file:\", pth)\n",
    "        print(\"Error:\", e)\n",
    "view raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary list for the input data\n",
    "X_test = []\n",
    "\n",
    "#list to append all the labels\n",
    "Y_test = []\n",
    "\n",
    "#looping through train data to create melspec and augment data\n",
    "for i, dat in tqdm(enumerate(audio_test)):\n",
    "        \n",
    "    try:\n",
    "        #generate melspec for original and augmented files\n",
    "        mel = get_melspec(dat)\n",
    "       \n",
    "        #Appending test melspec to list\n",
    "        X_test.append(mel)\n",
    "        Y_test.append(y_test[i])\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in file:\", pth)\n",
    "        print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the test and train data to numpy array\n",
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "\n",
    "Y_train = encoder.transform(Y_train).reshape([len(Y_train), 1])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "\n",
    "Y_test = encoder.transform(Y_test).reshape([len(Y_test), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, GRU\n",
    "from keras.callbacks import Callback, EarlyStopping\n",
    "\n",
    "#Initiating the model as Sequential\n",
    "model = Sequential()\n",
    "\n",
    "#Adding the CNN layers along with some drop outs and maxpooling\n",
    "model.add(Conv2D(64, 2, activation = 'relu', input_shape = (X_train.shape[1:])))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(128, 2, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(256, 2, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (4,4)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(512, 2, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (8,8)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#flattening the data to be passed to a dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Adding the dense layers\n",
    "model.add(Dense(2048, activation = 'relu'))\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "\n",
    "#final output layer with 10 predictions to be made\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "'''\n",
    "Optimizer = Adam\n",
    "Loss = Sparse Categorical CrossEntropy\n",
    "'''\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
