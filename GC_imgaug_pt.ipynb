{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopalaia/Progetto-Lab-IA/blob/main/GC_imgaug_pt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genre Classification via Image Augumentation"
      ],
      "metadata": {
        "id": "_-GryzY_nNTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questa implementazioni proviamo a sfruttare la tecnica di Image Augumentation, un processo di creazione di nuove immagini a partire da quelle esistenti in modo da allenare un modello con più dati. Andiamo allora ad applicare delle piccole modifiche alle immagini come, ad esempio, rendere una nuova immagine un po' più luminosa. Oppure potremmo ritagliare una parte dell'immagine originale, o ancora rifletterla su uno dei due assi. In generale l'intento rimane quello di ampliare il proprio dataset in modo da irrobustire il modello in fase di addestramento"
      ],
      "metadata": {
        "id": "laW06OQash3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "anhDuc-3EPKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Kel3OE5bEoXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ],
      "metadata": {
        "id": "mj_o81fssrN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.transforms import ToTensor,transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from skimage.io import imread, imsave\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FTw39_HFuXMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizziamo i dati"
      ],
      "metadata": {
        "id": "9uztgNu1cmrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"GTZAN Dataset/images_original\"\n",
        "img = mpimg.imread(img_path + '/rock/rock00093.png')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "print('Il formato dell\\'immagine è:', img.shape)"
      ],
      "metadata": {
        "id": "OltfVCgTs5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "im_size = (img.shape[0], img.shape[1])"
      ],
      "metadata": {
        "id": "NYYgMqu2wvzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funzioni"
      ],
      "metadata": {
        "id": "w6w8_W-Sjv4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo una funzione per ottenere i parametri di normalizzazione (media e varianza) di un dataset"
      ],
      "metadata": {
        "id": "zwZmmWpnj0LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization_parameter(dataloader):\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    nb_samples = len(dataloader.dataset)\n",
        "    for data,_ in tqdm(dataloader):\n",
        "        batch_samples = data.size(0)\n",
        "        data = data.view(batch_samples, data.size(1), -1)\n",
        "        mean += data.mean(2).sum(0)\n",
        "        std += data.std(2).sum(0)\n",
        "    mean /= nb_samples\n",
        "    std /= nb_samples\n",
        "    return mean.numpy(), std.numpy()"
      ],
      "metadata": {
        "id": "5kk8zxnGxHhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora definiamo un encoder e un decoder per mappare le classi in interi e viceversa"
      ],
      "metadata": {
        "id": "ouAwFtynlDEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(data):\n",
        "  classes = data.classes\n",
        "  encoder = {}\n",
        "  for i in range(len(classes)):\n",
        "    encoder[i] = classes[i]\n",
        "  return encoder\n",
        "\n",
        "def decoder(data):\n",
        "  classes = data.classes    \n",
        "  decoder = {}\n",
        "  for i in range(len(classes)):\n",
        "    decoder[classes[i]] = i\n",
        "  return decoder"
      ],
      "metadata": {
        "id": "S3mCicZgzkSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo quindi una funzione che stampa randomicamente dal dataset delle immagini"
      ],
      "metadata": {
        "id": "B8Jo7FEylXeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting random images from dataset\n",
        "def class_plot(data,n_figures = 12):\n",
        "  n_row = int(n_figures/4)\n",
        "  fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n",
        "  for ax in axes.flatten():\n",
        "    a = random.randint(0,len(data))\n",
        "    (image,label) = data[a]\n",
        "    #print(type(image))\n",
        "    label = int(label)\n",
        "    encoders = encoder(data)\n",
        "    l = encoders[label]\n",
        "    image = image.numpy().transpose(1,2,0)\n",
        "    im = ax.imshow(image)\n",
        "    ax.set_title(l)\n",
        "    ax.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kVvgGBI1zsjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepariamo i dati"
      ],
      "metadata": {
        "id": "E50cnJUjkdxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trasformazioni"
      ],
      "metadata": {
        "id": "45zZvMDCmDPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.Resize(im_size),\n",
        "                                       transforms.ToTensor()\n",
        "])\n",
        "train_data = torchvision.datasets.ImageFolder(root = img_path, transform = train_transforms)\n",
        "train_loader =  DataLoader(train_data, batch_size = batch_size , shuffle = True)\n",
        "mean, std = normalization_parameter(train_loader)"
      ],
      "metadata": {
        "id": "_XFyeYHdkBpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([transforms.Resize(im_size),\n",
        "                                        transforms.RandomResizedCrop(size = 315, scale = (0.95, 1.0)),\n",
        "                                        transforms.RandomRotation(degrees = 10),\n",
        "                                        transforms.RandomHorizontalFlip(),\n",
        "                                        transforms.CenterCrop(size = 299),  # standard di Image Net\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean, std)\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "                                        transforms.Resize(im_size),\n",
        "                                        transforms.CenterCrop(size = 299),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean, std)\n",
        "])"
      ],
      "metadata": {
        "id": "3wwGCTgGugNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creazione dataset"
      ],
      "metadata": {
        "id": "5KZ7M36KmFnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root = img_path, transform = train_transforms)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root = img_path, transform = test_transforms)"
      ],
      "metadata": {
        "id": "UYgXYz6bzf0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizziamo i dati nuovamente"
      ],
      "metadata": {
        "id": "aGSvsvjtlpHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prima dell'image augumentation"
      ],
      "metadata": {
        "id": "hyoc3Lzn0MtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_plot(train_data)"
      ],
      "metadata": {
        "id": "JuWTOqMR0H7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dopo l'image augumentation"
      ],
      "metadata": {
        "id": "vRnC2h6o0RpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_plot(dataset)"
      ],
      "metadata": {
        "id": "bTAWQd-zz3bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(43)\n",
        "val_size = int(len(dataset) * 0.2)\n",
        "train_size = len(dataset) - val_size"
      ],
      "metadata": {
        "id": "Gn83oems1F4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepariamo i dataset"
      ],
      "metadata": {
        "id": "Kbu-zgRKmW2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procediamo con un `random_split` per dividere il dataset completo in dei dataseti di addestramento, validazione e test"
      ],
      "metadata": {
        "id": "h3w0WPrdmd6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "id": "b2SHfKpr1Lnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "dKP6Olem1Tww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definiamo il modello"
      ],
      "metadata": {
        "id": "tm5o9XHHnF5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funzione di Accuracy"
      ],
      "metadata": {
        "id": "V8Y1P28pnq0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _,preds = torch.max(outputs, dim = 1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "oL9P1tRw1wYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modello"
      ],
      "metadata": {
        "id": "C-UYyVQOngDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_size, 1024)\n",
        "    self.linear2 = nn.Linear(1024, 512)\n",
        "    self.linear3 = nn.Linear(512, 128)\n",
        "    self.linear4 = nn.Linear(128, 32)\n",
        "    self.linear5 = nn.Linear(32, output_size)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    out = xb.view(xb.size(0), -1)\n",
        "    out = self.linear1(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.linear3(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.linear4(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.linear5(out)\n",
        "    return out\n",
        "\n",
        "  def training_step(self,batch):\n",
        "    image,labels = batch\n",
        "    out = self(image)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    return loss\n",
        "   \n",
        "  def validation_step(self, batch):\n",
        "    images, labels = batch \n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, labels)\n",
        "    acc = accuracy(out, labels)\n",
        "    return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()   # Combiniamo le Loss\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()      # Combiniamo le Accuracy\n",
        "    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "  def epoch_end(self, epoch, result):\n",
        "    print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "HtTsB9As14VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funzioni del modello"
      ],
      "metadata": {
        "id": "bkfoFHK_n8xI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo delle funzioni per addestrare e validare il modello"
      ],
      "metadata": {
        "id": "lADNze2_oEpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs,lr,model,train_loader,val_loader,opt_func=torch.optim.SGD):\n",
        "  history = []\n",
        "  optimizer = opt_func(model.parameters(),lr)\n",
        "  for epoch in range(epochs):\n",
        "    # Training Phase \n",
        "    for batch in train_loader:\n",
        "      loss = model.training_step(batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "    # Validation phase\n",
        "    result = evaluate(model, val_loader)\n",
        "    model.epoch_end(epoch, result)\n",
        "    history.append(result)\n",
        "  return history"
      ],
      "metadata": {
        "id": "qjdKdsjY2V1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "  losses = [x['val_loss'] for x in history]\n",
        "  plt.plot(losses, '-x')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "def plot_accuracies(history):\n",
        "  accuracies = [x['val_acc'] for x in history]\n",
        "  plt.plot(accuracies, '-x')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.title('Accuracy vs. No. of epochs');"
      ],
      "metadata": {
        "id": "bUNwxEbJ2itN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "lExMhblUous7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo il nostro data loader. La scelta del device a cui assegnare le risorse avverrà direttamente da qui"
      ],
      "metadata": {
        "id": "2SDSkxVVoyZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "GMrVrkc820AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data, device):\n",
        "  \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "  if isinstance(data, (list,tuple)):\n",
        "    return [to_device(x, device) for x in data]\n",
        "  return data.to(device, non_blocking=True)\n",
        "\n",
        "class DataLoader():\n",
        "  \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "  def __init__(self, dl, device):\n",
        "    self.dl = dl\n",
        "    self.device = device\n",
        "        \n",
        "  def __iter__(self):\n",
        "    \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "    for b in self.dl: \n",
        "      yield to_device(b, self.device)\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Number of batches\"\"\"\n",
        "    return len(self.dl)"
      ],
      "metadata": {
        "id": "B0tF6P7H2536"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_loader, device)\n",
        "val_loader = DataLoader(val_loader, device)\n",
        "test_loader = DataLoader(test_loader, device)"
      ],
      "metadata": {
        "id": "RAnZcPzV3HPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "LoPI_ClLpMfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(Model(3 * 299 * 299, 10), device)"
      ],
      "metadata": {
        "id": "sqrJpNUp3Nut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "print(history)"
      ],
      "metadata": {
        "id": "ee0FZ4gS3QLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = { 1e-2 : 50, 1e-3 : 50, 1e-5 : 50, 1e-6 : 50}"
      ],
      "metadata": {
        "id": "5u-wP7u23ess"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lr,epoch in epochs.items():\n",
        "    history += fit(epoch,lr, model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "YXjQucYx3iXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "pOOGTD3638ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "t8VoXrCF3_MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "GQVEs7n4pm_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'models/pt/GC_imgaug/GC_imgaug.pth')"
      ],
      "metadata": {
        "id": "RDHXNKDA4eN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(3 * 299 * 299, 10)\n",
        "model.load_state_dict(torch.load('models/pt/GC_imgaug/GC_imgaug.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "1kciQlto4bvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = evaluate(model, test_loader)"
      ],
      "metadata": {
        "id": "cZC-WsSt4Dze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test['val_acc']\n",
        "test_loss = test['val_loss']\n",
        "print(\"Accuracy:\", test_acc)\n",
        "print(\"Loss:\", test_loss)"
      ],
      "metadata": {
        "id": "xFt3cTxA4HvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[manca prediction]"
      ],
      "metadata": {
        "id": "pcwuK8ygp4Nx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9uztgNu1cmrW",
        "w6w8_W-Sjv4l",
        "45zZvMDCmDPW"
      ],
      "name": "GC_imgaug_pt.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Wxt-3pofa9rg_A9z9I-2eTfpzazSwNOt",
      "authorship_tag": "ABX9TyMdihuywxWZRjcJMBQcuG7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}